# [CI/CD Pipeline]

* Deciders: Colin Young, Stella Ma, Josh Cross, Abdelkader Laouini (LA), Benny Cai, Nawwar Tohme, Edgar Flores, Zeven Vidmar-Barker
* Date: 2021-02-7

## Context and Problem Statement
We want to choose what structure we want to use for the CI/CD pipeline:
1. linting and code style enforcement (may happen in pipeline and/or in editor)
2. code quality via tool  (ex. Codeclimate, Codacy, etc.)
3. code quality via human review (ex. Pull Requests)
4. unit tests via automation (ex. Jest, Tape, Ava, Cypress, Mocha/Chai, etc.)*
5. documentation generation via automation (ex. JSDocs)


## Considered Options
* linting and code style enforcement 
  * Super-Linter
* Code quality via tool
  * Codeclimate
  * Codacy
* Code quality via human review
  * Pull Requests
* Unit tests via automation
  * Jest
  * Tape
  * Ava
  * Cypress
  * Mocha/Chai
* Documentation generation via automation
  * JSDocs

## Decision Outcome

Chosen option: "[option 1]", because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | … | comes out best (see below)].


### [option 1]

[example | description | pointer to more information | …] <!-- optional -->

* Good, because [argument a]
* Good, because [argument b]
* Bad, because [argument c]
* … <!-- numbers of pros and cons can vary -->




